{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'artist', 'song', 'lyrics'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "song_theme = pd.read_json('./Dataset/top_songs_lyrics.json')\n",
    "song_theme.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA) - 165 songs\n",
    "\n",
    "**Three major ideas**\n",
    "- Translate songs in native language to english\n",
    "- pre-processing: Clean and tokenize the translated lyrics, remove stopwords (common and custom)\n",
    "- Topic Modelling: Create an LDA model to identify topics within the song lyrics\n",
    "\n",
    "**Detailed Steps**\n",
    "1) Importing libraries\n",
    "    - googletrans: handle text transaltion\n",
    "    - string: provides constants for string manipulation \n",
    "    - nltk: A toolkit for natural language processing (NLP)\n",
    "    - gensim: Used for topic modelling\n",
    "\n",
    "2) Initialize Translator\n",
    "\n",
    "3) Define Translation Function\n",
    "\n",
    "4) Translate Lyrics\n",
    "\n",
    "5) Define Stopwords\n",
    "    - default_stopwords: default set of english stopwords from NLTK\n",
    "    - custom_stopwords: I manually added them.\n",
    "\n",
    "6) Pre-process Lyrics Function\n",
    "    - Remove punctuation\n",
    "    - convert lyrics to lowercase\n",
    "    - tokenize lyrics into words\n",
    "    - filter out non-alphabetic words and stopwords\n",
    "\n",
    "7) Apply pre-preprocessing\n",
    "    \n",
    "8) Perform Topic Modelling with LDA\n",
    "    - dictionary: maps each unqiue word to an ID\n",
    "    - corpus: transform the tokens into a bag-of-words format\n",
    "    - lda_model: creates an LDA model with 10 topics and trains it on the corpus for 15 passes \n",
    "    - extracts and prints the top 5 words for each topic found by the LDA model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.038*\"star\" + 0.015*\"dancing\" + 0.014*\"make\" + 0.014*\"know\" + 0.012*\"money\"')\n",
      "(1, '0.026*\"baby\" + 0.021*\"know\" + 0.015*\"side\" + 0.014*\"rain\" + 0.014*\"come\"')\n",
      "(2, '0.017*\"know\" + 0.016*\"wake\" + 0.012*\"middle\" + 0.011*\"good\" + 0.011*\"let\"')\n",
      "(3, '0.039*\"try\" + 0.024*\"never\" + 0.023*\"get\" + 0.017*\"fall\" + 0.016*\"meant\"')\n",
      "(4, '0.052*\"love\" + 0.018*\"know\" + 0.015*\"body\" + 0.013*\"touch\" + 0.010*\"used\"')\n",
      "(5, '0.054*\"somebody\" + 0.053*\"love\" + 0.046*\"fuck\" + 0.039*\"find\" + 0.020*\"come\"')\n",
      "(6, '0.070*\"work\" + 0.012*\"lose\" + 0.009*\"night\" + 0.008*\"kiss\" + 0.008*\"always\"')\n",
      "(7, '0.030*\"every\" + 0.028*\"love\" + 0.024*\"day\" + 0.022*\"baby\" + 0.020*\"want\"')\n",
      "(8, '0.023*\"go\" + 0.022*\"let\" + 0.015*\"want\" + 0.015*\"need\" + 0.012*\"never\"')\n",
      "(9, '0.050*\"girls\" + 0.023*\"run\" + 0.022*\"world\" + 0.020*\"know\" + 0.016*\"little\"')\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora, models\n",
    "\n",
    "# #download stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "#initilaize translator \n",
    "translator = Translator()\n",
    "\n",
    "#define function to translate lyrics to english\n",
    "def translate_lyrics(lyrics):\n",
    "    try:\n",
    "        return translator.translate(lyrics, dest='en').text\n",
    "    except Exception as e:\n",
    "        print (f'Error in Transaltion: {e}')\n",
    "        return lyrics\n",
    "\n",
    "#translate lyrics to english\n",
    "song_theme['translated_lyrics'] = song_theme['lyrics'].apply(translate_lyrics)\n",
    "\n",
    "# get the list of stopwords - default & custom\n",
    "default_stopwords = set(stopwords.words('english'))\n",
    "custom_stopwords = default_stopwords.union(\n",
    "    {'verse', 'chorus', '–', 'im', 'oh', 'na', 'yeah', 'got', 'ooh', 'wan', 'cause', 'ill', 'youre', '2', '1', \n",
    "     'ft', 'like', 'one', 'prechorus','la', 'aint', 'low', 'two', 'woah', 'gettin', 'postchorus', 'mmm', 'mxrxgxa', 'da', 'thank',\n",
    "     'ah', 'gon', 'ya', \"’\", 'thats', 'another', 'outro', 'ive', 'hey', 'montenero', 'whats', 'gioielli', 'clap', 'del', 'blue', 'zyrtck',\n",
    "     'bridge', 'dj', 'would', 'way', 'ta', 'em', 'yes', 'youd', 'didnt', 'nothin', 'nothing', 'ayy',\n",
    "     'maybe', 'redrum', 'ohoh', 'ariana', 'vacca', 'bout', 'grande', '21', 'youve', 'youll', 'somethin', 'beyoncé',\n",
    "     'id', 'smack', 'yo', 'freestyle', 'without', 'di', 'intro', 'woo', 'might', 'il', 'non', 'uh', 'knew', 'mm',\n",
    "     'anybody', 'hes', 'ima', 'e', 'x', 'itll', 'refrain', 'could', 'ee', 'comin', 'lil', 'shes', '3', 'halo', 'whats', \n",
    "     'gionni', 'sometimes', 'gunz', 'ride', 'blow', 'black','mutha', 'uhoh', 'pai', 'zeno', 'wouldnt', 'air',\n",
    "     'egreen', 'toni', 'georgia', 'throw', 'nah', 'cease', 'goes', 'dust', 'bet', 'bum', 'apart', 'doesnt', 'cassel', 'oohoohoohooh', \n",
    "     'huh', 'closet', 'goin', 'cleanin', 'claver', 'closet', 'nex', 'lot', 'michaels', 'less', 'things', 'per', 'second', 'line',\n",
    "     'bites', 'shall', 'everybody', 'ele', 'fit', 'ho', 'jp', 'joe', 'smokestackstudio', 'getting', 'aleaka', 'three',\n",
    "     })\n",
    "\n",
    "#pre-process the lyrics function\n",
    "def preprocess_lyrics(lyrics):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    tokens = word_tokenize(lyrics.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in custom_stopwords]\n",
    "    return tokens\n",
    "\n",
    "#apply pre-processing using the TRANSLATED lyrics\n",
    "song_theme['tokens'] = song_theme['translated_lyrics'].apply(preprocess_lyrics)\n",
    "\n",
    "#PERFORM TOPIC MODELLING\n",
    "\n",
    "#create dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(song_theme['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in song_theme['tokens']]\n",
    "\n",
    "#build LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)\n",
    "\n",
    "#print topics \n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize distribution of Topics from LDA model\n",
    "\n",
    "1) Visualize topic distibution per document\n",
    "    - a document refers to individual unit of text that's being analzyed.\n",
    "    - i have 165 songs in my data frame, it means i have 165 documents\n",
    "    \n",
    "2) Visualize topic distribution using pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract themes for each song using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>translated_lyrics</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Probability</th>\n",
       "      <th>Topic_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Thinking out Loud</td>\n",
       "      <td>[Verse 1]\\nWhen your legs don't work like they...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>[love, know, body, touch, used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norah Jones</td>\n",
       "      <td>Come Away With Me</td>\n",
       "      <td>[Verse 1]\\nCome away with me in the night\\nCom...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.983014</td>\n",
       "      <td>[every, love, day, baby, want]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Troye Sivan</td>\n",
       "      <td>Happy Little Pill</td>\n",
       "      <td>[Verse 1]\\nIn the crowd, alone\\nAnd every seco...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>[girls, run, world, know, little]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Script</td>\n",
       "      <td>Superheroes</td>\n",
       "      <td>[Verse 1]\\nAll her life, she has seen\\nOh the ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>[every, love, day, baby, want]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellie Goulding</td>\n",
       "      <td>How Long Will I Love You</td>\n",
       "      <td>[Intro]\\nMm\\nMm\\n[Verse 1]\\nHow long will I lo...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.981246</td>\n",
       "      <td>[somebody, love, fuck, find, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Rossa</td>\n",
       "      <td>Takkan Berpaling DariMu</td>\n",
       "      <td>[Lyrics \"Takkan Turning from You\"]\\n[VERSE]\\nA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725387</td>\n",
       "      <td>[baby, know, side, rain, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Hozier</td>\n",
       "      <td>Too Sweet</td>\n",
       "      <td>[Verse 1]\\nIt can't be said I'm an early bird\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981141</td>\n",
       "      <td>[baby, know, side, rain, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Hozier</td>\n",
       "      <td>Work Song</td>\n",
       "      <td>[Intro]\\nMmm, mmm, mmm, mmm\\nMmm, mmm, mmm, mm...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993428</td>\n",
       "      <td>[baby, know, side, rain, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Coi Leray</td>\n",
       "      <td>Players</td>\n",
       "      <td>[Chorus]\\nYeah, 'cause girls is players too\\nU...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825295</td>\n",
       "      <td>[go, let, want, need, never]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>R.E.M</td>\n",
       "      <td>[Intro: Ariana Grande]\\nMm-mm\\n[Verse 1: Arian...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.892688</td>\n",
       "      <td>[know, wake, middle, good, let]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                      song  \\\n",
       "0        Ed Sheeran         Thinking out Loud   \n",
       "1       Norah Jones         Come Away With Me   \n",
       "2       Troye Sivan         Happy Little Pill   \n",
       "3        The Script               Superheroes   \n",
       "4    Ellie Goulding  How Long Will I Love You   \n",
       "..              ...                       ...   \n",
       "160           Rossa   Takkan Berpaling DariMu   \n",
       "161          Hozier                 Too Sweet   \n",
       "162          Hozier                 Work Song   \n",
       "163       Coi Leray                   Players   \n",
       "164   Ariana Grande                     R.E.M   \n",
       "\n",
       "                                     translated_lyrics  Dominant_Topic  \\\n",
       "0    [Verse 1]\\nWhen your legs don't work like they...               4   \n",
       "1    [Verse 1]\\nCome away with me in the night\\nCom...               7   \n",
       "2    [Verse 1]\\nIn the crowd, alone\\nAnd every seco...               9   \n",
       "3    [Verse 1]\\nAll her life, she has seen\\nOh the ...               7   \n",
       "4    [Intro]\\nMm\\nMm\\n[Verse 1]\\nHow long will I lo...               5   \n",
       "..                                                 ...             ...   \n",
       "160  [Lyrics \"Takkan Turning from You\"]\\n[VERSE]\\nA...               1   \n",
       "161  [Verse 1]\\nIt can't be said I'm an early bird\\...               1   \n",
       "162  [Intro]\\nMmm, mmm, mmm, mmm\\nMmm, mmm, mmm, mm...               1   \n",
       "163  [Chorus]\\nYeah, 'cause girls is players too\\nU...               8   \n",
       "164  [Intro: Ariana Grande]\\nMm-mm\\n[Verse 1: Arian...               2   \n",
       "\n",
       "     Topic_Probability                         Topic_Words  \n",
       "0             0.993331     [love, know, body, touch, used]  \n",
       "1             0.983014      [every, love, day, baby, want]  \n",
       "2             0.993959   [girls, run, world, know, little]  \n",
       "3             0.995754      [every, love, day, baby, want]  \n",
       "4             0.981246  [somebody, love, fuck, find, come]  \n",
       "..                 ...                                 ...  \n",
       "160           0.725387      [baby, know, side, rain, come]  \n",
       "161           0.981141      [baby, know, side, rain, come]  \n",
       "162           0.993428      [baby, know, side, rain, come]  \n",
       "163           0.825295        [go, let, want, need, never]  \n",
       "164           0.892688     [know, wake, middle, good, let]  \n",
       "\n",
       "[165 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to get the dominant topic for a single document\n",
    "def get_dominant_topic(lda_model, corpus_document):\n",
    "    topic_distribution = lda_model.get_document_topics(corpus_document)\n",
    "    dominant_topic = max(topic_distribution, key=lambda x:x[1])\n",
    "    return dominant_topic[0], dominant_topic[1]\n",
    "\n",
    "#apply the function to each doument in the corpus\n",
    "dominant_topics = [get_dominant_topic(lda_model, doc) for doc in corpus]\n",
    "\n",
    "#create a dataframe with the results\n",
    "theme_df = pd.DataFrame(dominant_topics, columns=['Dominant_Topic', 'Topic_Probability'])\n",
    "\n",
    "#add theme df to original df\n",
    "song_theme = pd.concat([song_theme, theme_df], axis=1)\n",
    "\n",
    "#function to get the top N words for a given topic\n",
    "def get_topic_words(lda_model, topic_id, n_words=5):\n",
    "    return [word for word, _ in lda_model.show_topic(topic_id, topn=n_words)]\n",
    "\n",
    "# add a column with the top words for each song's 'dominatn topic\n",
    "song_theme['Topic_Words'] = song_theme['Dominant_Topic'].apply(lambda x:get_topic_words(lda_model, x))\n",
    "\n",
    "\n",
    "song_theme[['artist','song', 'translated_lyrics', 'Dominant_Topic', 'Topic_Probability', 'Topic_Words']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save df to a csv file \n",
    "# csv_path = './Dataset/LDA_sentiment.csv'\n",
    "# song_theme.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
